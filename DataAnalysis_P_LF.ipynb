{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2cab95-9861-43d4-94bf-a6b92b2e10aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe1bd89-133b-4dbc-bd44-f4217d237517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Empty or Corrupted P6_V1_LE1.txt, skipping...\n",
      "Not Found P9_V1_LF1.txt\n",
      "Not Found P9_V1_LF2.txt\n",
      "Not Found P9_V1_LF3.txt\n",
      "Not Found P9_V1_LF4.txt\n",
      "Not Found P9_V1_LF5.txt\n",
      "Not Found P9_V1_LF6.txt\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P26\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P27\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P31\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P33\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P35\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P36\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P40\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P41\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P47\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P53\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P54\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P58\\Visit 1\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P61\\Visit 1\\Left, skipping...\n",
      "Not Found P9_V1_RF1.txt\n",
      "Not Found P9_V1_RF2.txt\n",
      "Not Found P9_V1_RF3.txt\n",
      "Not Found P9_V1_RF4.txt\n",
      "Not Found P9_V1_RF5.txt\n",
      "Not Found P9_V1_RF6.txt\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P26\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P27\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P31\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P33\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P35\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P36\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P40\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P41\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P47\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P53\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P54\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P58\\Visit 1\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P61\\Visit 1\\Right, skipping...\n",
      "Not Found P4_V2_LE1.txt\n",
      "Not Found P4_V2_LE2.txt\n",
      "Not Found P4_V2_LE3.txt\n",
      "Not Found P4_V2_LF1.txt\n",
      "Not Found P4_V2_LF2.txt\n",
      "Not Found P4_V2_LF3.txt\n",
      "Not Found P9_V2_LF1.txt\n",
      "Not Found P9_V2_LF2.txt\n",
      "Not Found P9_V2_LF3.txt\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P26\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P27\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P31\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P33\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P35\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P36\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P40\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P41\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P47\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P49\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P53\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P54\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P58\\Visit 2\\Left, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P61\\Visit 2\\Left, skipping...\n",
      "Not Found P4_V2_RF2.txt\n",
      "Not Found P4_V2_RF3.txt\n",
      "Not Found P9_V2_RF1.txt\n",
      "Not Found P9_V2_RF2.txt\n",
      "Not Found P9_V2_RF3.txt\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P26\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P27\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P31\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P33\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P35\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P36\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P40\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P41\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P47\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P49\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P53\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P54\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P58\\Visit 2\\Right, skipping...\n",
      "Directory not found: C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P61\\Visit 2\\Right, skipping...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# z will be the participant ID, X will be the visit, and y will be foot\n",
    "\n",
    "for xx in range(1,3):\n",
    "    TE_final = []\n",
    "    T_extension = []\n",
    "    Edataframes = []\n",
    "    TF_final = []\n",
    "    T_flexion = []\n",
    "    Fdataframes = []\n",
    "    if xx == 1:  \n",
    "        x = \"V1\"\n",
    "        X = \"Visit 1\"\n",
    "        trialvar = 6\n",
    "    else:  \n",
    "        x = \"V2\"\n",
    "        X = \"Visit 2\"\n",
    "        trialvar = 3\n",
    "\n",
    "\n",
    "    for yy in range(1, 3):  \n",
    "        TE_final = []\n",
    "        T_extension = []\n",
    "        Edataframes = []\n",
    "        TF_final = []\n",
    "        T_flexion = []\n",
    "        Fdataframes = []\n",
    "        if yy == 1:  \n",
    "            y = \"L\"\n",
    "            Y = \"Left\"\n",
    "        else:  \n",
    "            y = \"R\"\n",
    "            Y = \"Right\"\n",
    "        \n",
    "            \n",
    "    \n",
    "        for z in range(1, 62):  \n",
    "            dir_path_ext = fr\"C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P{z}\\{X}\\{Y}\"\n",
    "            dir_path_flx = fr\"C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\\P{z}\\{X}\\{Y}\" \n",
    "            import numpy as np\n",
    "            import pandas as pd\n",
    "            import matplotlib.pyplot as plt\n",
    "            if not os.path.exists(dir_path_ext):\n",
    "                print(f\"Directory not found: {dir_path_ext}, skipping...\")\n",
    "                continue\n",
    "                        \n",
    "            # Extension Variables\n",
    "            Max_N_ext = []\n",
    "            TimesFound_ext = []\n",
    "            Avg_N_ext = []\n",
    "            Std_ext = []\n",
    "            AboveAvg_N_ext = []\n",
    "            rise_time80_ext = []\n",
    "            Participant_ID_ext = []\n",
    "            max80_ext = []\n",
    "            RateForceDevelopmet_ext = []\n",
    "            Trial_num_ext = []\n",
    "            Diff_NE = []\n",
    "            Var_ext = []\n",
    "            # Flexion Variables\n",
    "            Max_N_flx = []\n",
    "            TimesFound_flx = []\n",
    "            Avg_N_flx = []\n",
    "            Std_flx = []\n",
    "            AboveAvg_N_flx = []\n",
    "            rise_time80_flx = []\n",
    "            Participant_ID_flx = []\n",
    "            max80_flx = []\n",
    "            RateForceDevelopmet_flx = []\n",
    "            Trial_num_flx = []\n",
    "            Diff_NF = []\n",
    "            Var_flx = []\n",
    "            \n",
    "            # Function to find the index closest to a specific percentage of the peak value\n",
    "            def find_index_at_percentage_ext(data, percentage):\n",
    "                return np.argmax(data >= np.max(data) * percentage)\n",
    "                # Function to find the index closest to a specific percentage of the peak value\n",
    "            def find_index_at_percentage_flx(data, percentage):\n",
    "                return np.argmin(data <= np.min(data) * percentage)\n",
    "            \n",
    "            # Check if files exist in the directory\n",
    "            Efiles_in_directory = os.listdir(dir_path_ext)\n",
    "            Ffiles_in_directory = os.listdir(dir_path_flx)\n",
    "            \n",
    "            # Loop through all six trials for extension data\n",
    "            for trial_ext in range(1, trialvar+1):\n",
    "                file_ename = f\"P{z}_{x}_{y}E{trial_ext}.txt\"\n",
    "                count = 0;\n",
    "                if not file_ename in Efiles_in_directory:\n",
    "                    print(f\"Not Found {file_ename}\")\n",
    "                    count = count + 1\n",
    "                    continue\n",
    "                data_ext = pd.read_csv(os.path.join(dir_path_ext, file_ename))\n",
    "                if data_ext.empty or data_ext.shape[1] < 2:\n",
    "                    print(f\"File Empty or Corrupted {file_ename}, skipping...\")\n",
    "                    continue\n",
    "                \n",
    "                data_ext = data_ext*9.8\n",
    "                x_ext = np.linspace(0, 10, len(data_ext.iloc[:, 1]))  # Access first column\n",
    "                maxVal_N_ext = np.max(data_ext.iloc[:, 1])\n",
    "                PE_ID = z\n",
    "                \n",
    "                # Find index corresponding to %80 and %100 of the peak value\n",
    "                index_80_percent_ext = find_index_at_percentage_ext(data_ext.iloc[:, 1], 0.8)\n",
    "                # Calculate 80% rise time\n",
    "                riseTime80_trial_ext = x_ext[index_80_percent_ext] - x_ext[1]\n",
    "                rise_time80_ext.append(riseTime80_trial_ext)\n",
    "            \n",
    "                max80_trial_ext = maxVal_N_ext * 0.8\n",
    "                RFP_ext = (max80_trial_ext)/riseTime80_trial_ext\n",
    "                # All the vertcat functions add the values to the table\n",
    "                Max_N_ext.append(maxVal_N_ext)\n",
    "                TimesFound_ext.append(np.sum(data_ext.iloc[:,1] == np.max(data_ext.iloc[:,1])))\n",
    "                Trial_num_ext.append(trial_ext)\n",
    "                avg_N_ext = np.mean(data_ext.iloc[:,1][index_80_percent_ext:])\n",
    "                std_ext = np.std(data_ext.iloc[:,1][index_80_percent_ext:])\n",
    "                Avg_N_ext.append(avg_N_ext)\n",
    "                Std_ext.append(std_ext)\n",
    "                max80_ext.append(max80_trial_ext)\n",
    "                Participant_ID_ext.append(PE_ID)\n",
    "                RateForceDevelopmet_ext.append(RFP_ext)\n",
    "                AboveAvg_N_ext.append(np.sum(data_ext.iloc[:,1][index_80_percent_ext:] >= avg_N_ext) * 100 / len(data_ext.iloc[:,1]))\n",
    "                Diff_NE.append(avg_N_ext - max80_trial_ext)\n",
    "                tse = data_ext.iloc[:,1][index_80_percent_ext:]\n",
    "                var_ext = np.var(tse)\n",
    "                Var_ext.append(var_ext)\n",
    "\n",
    "            # Loop through all six trials for flexion data\n",
    "            for trial_flx in range(1, trialvar+1):\n",
    "                file_fname = f\"P{z}_{x}_{y}F{trial_flx}.txt\"\n",
    "                count = 0;\n",
    "                if not file_fname in Ffiles_in_directory:\n",
    "                    print(f\"Not Found {file_fname}\")\n",
    "                    count = count + 1\n",
    "                    continue\n",
    "                data_flx = pd.read_csv(os.path.join(dir_path_flx, file_fname))\n",
    "                if data_flx.empty or data_ext.shape[1] < 2:\n",
    "                    print(f\"File Empty or Corrupted {file_fname}\")\n",
    "                    continue\n",
    "                data_flx = data_flx*9.8\n",
    "                x_flx = np.linspace(0, 10, len(data_flx.iloc[:, 1]))  # Access first column\n",
    "                maxVal_N_flx = np.min(data_flx.iloc[:, 1])\n",
    "                PF_ID = z\n",
    "                \n",
    "                # Find index corresponding to %80 of the peak value\n",
    "                index_80_percent_flx = find_index_at_percentage_flx(data_flx.iloc[:, 1], 0.8)\n",
    "                # Calculate 80% rise time\n",
    "                riseTime80_trial_flx = x_flx[index_80_percent_flx] - x_flx[1]\n",
    "                rise_time80_flx.append(riseTime80_trial_flx)\n",
    "            \n",
    "                max80_trial_flx = maxVal_N_flx * 0.8\n",
    "                RFP_flx = (max80_trial_flx)/riseTime80_trial_flx\n",
    "                # All the vertcat functions add the values to the table\n",
    "                Max_N_flx.append(maxVal_N_flx)\n",
    "                TimesFound_flx.append(np.sum(data_flx.iloc[:,1] == maxVal_N_flx))\n",
    "                Trial_num_flx.append(trial_flx)\n",
    "                avg_N_flx = np.mean(data_flx.iloc[:,1][index_80_percent_flx:]) \n",
    "                std_flx = np.std(data_flx.iloc[:,1][index_80_percent_flx:])\n",
    "                Avg_N_flx.append(avg_N_flx)\n",
    "                Std_flx.append(std_flx)\n",
    "                max80_flx.append(max80_trial_flx)\n",
    "                Participant_ID_flx.append(PF_ID)\n",
    "                RateForceDevelopmet_flx.append(RFP_flx)\n",
    "                AboveAvg_N_flx.append(np.sum(data_flx.iloc[:,1][index_80_percent_flx:] <= avg_N_flx) * 100 / len(data_flx.iloc[:,1]))\n",
    "                Diff_NF.append(avg_N_flx - max80_trial_flx)\n",
    "                tsf = data_flx.iloc[:,1][index_80_percent_flx:]\n",
    "                var_flx = np.var(tsf)\n",
    "                Var_flx.append(var_flx)\n",
    "            \n",
    "        # Creating Extension Table for Each participant\n",
    "            T_extension = pd.DataFrame({\n",
    "                'PE ID': Participant_ID_ext,\n",
    "                f'Trial {y}': Trial_num_ext,\n",
    "                f'Max N {y}': Max_N_ext,\n",
    "                f'80%Max N {y}' : max80_ext,\n",
    "                f'Std {y}': Std_ext,\n",
    "                f'TimesFound {y}': TimesFound_ext,\n",
    "                f'Avg N {y}': Avg_N_ext,\n",
    "                f'AboveAvg% {y}': AboveAvg_N_ext,\n",
    "                f'RiseTime80{y}': rise_time80_ext,\n",
    "                f'RFP {y}': RateForceDevelopmet_ext,\n",
    "                f'Diff N {y}': Diff_NE,\n",
    "                f'Var {y}': Var_ext,\n",
    "            })\n",
    "           # Adding new table to bigger data frame\n",
    "            Edataframes.append(T_extension)\n",
    "            TE_final = pd.concat(Edataframes, ignore_index=True)\n",
    "\n",
    "        # Creating Flexion Table for Each participant\n",
    "            T_flexion = pd.DataFrame({\n",
    "                'PF ID': Participant_ID_flx,\n",
    "                f'Trial {y}': Trial_num_flx,\n",
    "                f'Max N {y}': Max_N_flx,\n",
    "                f'80%Max N {y}' : max80_flx,\n",
    "                f'Std {y}': Std_flx,\n",
    "                f'TimesFound {y}': TimesFound_flx,\n",
    "                f'Avg N {y}': Avg_N_flx,\n",
    "                f'AboveAvg % {y}': AboveAvg_N_flx,\n",
    "                f'RiseTime80 {y}': rise_time80_flx,\n",
    "                f'RFP {y}': RateForceDevelopmet_flx,\n",
    "                f'Diff N {y}': Diff_NF,\n",
    "                f'Var {y}': Var_flx,\n",
    "            })\n",
    "           # Adding new table to bigger data frame\n",
    "            Fdataframes.append(T_flexion)\n",
    "            TF_final = pd.concat(Fdataframes, ignore_index=True)\n",
    "\n",
    "        \n",
    "        # Saving Extension Table as an Excel File \n",
    "        folder_path = fr\"C:\\Users\\Luciana\\OneDrive - University of Florida\\Year 4\\TOP Lab\\GTH_Data_complete_Dataset\"\n",
    "        file_pathE = os.path.join(folder_path, f'DataAnalysis_Extension_{X}_table.xlsx')\n",
    "        sheet_name = fr\"Sheet {Y}_{X}\"   \n",
    "        # Check if file exists before writing\n",
    "        if os.path.exists(file_pathE):\n",
    "            # Append to an existing file without overwriting it\n",
    "            with pd.ExcelWriter(file_pathE, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "                TE_final.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        else:\n",
    "            # Create a new file\n",
    "            TE_final.to_excel(file_pathE, sheet_name=sheet_name, index=False)\n",
    "        # Saving Table as an Excel File for Extension Averages\n",
    "        file_pathEA = os.path.join(folder_path, f'DataAnalysis_AverageExtension_{X}_table.xlsx')\n",
    "        average_Eresults_df = TE_final.groupby('PE ID').mean().reset_index()\n",
    "        average_Eresults_df = average_Eresults_df.sort_values(by='PE ID')\n",
    "        sheet_name = fr\"Sheet Average {Y}_{X}\"\n",
    "        # Check if file exists before writing\n",
    "        if os.path.exists(file_pathEA):\n",
    "            # Append to an existing file without overwriting it\n",
    "            with pd.ExcelWriter(file_pathEA, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "                average_Eresults_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        else:\n",
    "            # Create a new file\n",
    "            average_Eresults_df.to_excel(file_pathEA, sheet_name=sheet_name, index=False)\n",
    "\n",
    "        # Saving Flexion Table as an Excel File \n",
    "        file_pathF = os.path.join(folder_path, f'DataAnalysis_Flexion_{X}_table.xlsx')\n",
    "        sheet_name = fr\"Sheet {Y}_{X}\"   \n",
    "        # Check if file exists before writing\n",
    "        if os.path.exists(file_pathF):\n",
    "            # Append to an existing file without overwriting it\n",
    "            with pd.ExcelWriter(file_pathF, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "                TF_final.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        else:\n",
    "            # Create a new file\n",
    "            TF_final.to_excel(file_pathF, sheet_name=sheet_name, index=False)\n",
    "        # Saving Table as an Excel File for Flexion Averages\n",
    "        file_pathFA = os.path.join(folder_path, f'DataAnalysis_AverageFlexion_{X}_table.xlsx')\n",
    "        average_Fresults_df = TF_final.groupby('PF ID').mean().reset_index()\n",
    "        average_Fresults_df = average_Fresults_df.sort_values(by='PF ID')\n",
    "        sheet_name = fr\"Sheet Average {Y}_{X}\"\n",
    "        # Check if file exists before writing\n",
    "        if os.path.exists(file_pathFA):\n",
    "            # Append to an existing file without overwriting it\n",
    "            with pd.ExcelWriter(file_pathFA, mode='a', engine='openpyxl', if_sheet_exists='replace') as writer:\n",
    "                average_Fresults_df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        else:\n",
    "            # Create a new file\n",
    "            average_Fresults_df.to_excel(file_pathFA, sheet_name=sheet_name, index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
